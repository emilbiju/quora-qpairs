{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe_100d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWaKdcpyxNXiW6Ogm8aF78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilbiju/quora-qpairs/blob/Pavan-Vemuri/GloVe_100d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7_mq-nLkmNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ff5dc8a2-0c57-4567-d145-6189d29ee718"
      },
      "source": [
        "from pylab import *\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "prefix = '/content/drive/My Drive/EE5180/Project/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-1wh5qmk3QU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6d98da5a-6f23-4e8d-b008-7ae9f416bc5c"
      },
      "source": [
        "#Creating dictionary of embeddings\n",
        "embeddings_index = {}\n",
        "f = open(prefix+'glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0] ## The first entry is the word\n",
        "    coefs = np.asarray(values[1:], dtype='float32') ## These are the vecotrs representing the embedding for the word\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "#Raw Data\n",
        "data = pd.read_csv(prefix + \"questions.csv\")\n",
        "data = data.drop(['id','qid1','qid2'],axis=1)\n",
        "dataArray = column_stack((data.question1,data.question2,data.is_duplicate))\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0  What is the step by step guide to invest in sh...  ...            0\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...  ...            0\n",
              "2  How can I increase the speed of my internet co...  ...            0\n",
              "3  Why am I mentally very lonely? How can I solve...  ...            0\n",
              "4  Which one dissolve in water quikly sugar, salt...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VEMzpAl-3u8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "399a769a-9324-4896-ba98-014f0d67d782"
      },
      "source": [
        "test_data, gg = train_test_split(dataArray, test_size= 0.9)\n",
        "rest, train_data = train_test_split(gg, test_size= 0.5)\n",
        "print(len(test_data),len(train_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40435 181958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD8FuHvllJBd",
        "colab_type": "text"
      },
      "source": [
        "# 100d GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7QVxxmBlO6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcess(doc):\n",
        "  processed = []; uk=[[],[]]\n",
        "  for i in range(2):\n",
        "    doc_processed = str(doc[i]).lower()\n",
        "    translator = str.maketrans('','',(string.punctuation))\n",
        "    doc_processed = doc_processed.translate(translator)\n",
        "    doc_processed = word_tokenize(doc_processed)\n",
        "    vect = zeros(100)\n",
        "    for word in doc_processed:\n",
        "      if word in embeddings_index:\n",
        "        vect = vect + embeddings_index[word]\n",
        "      else:\n",
        "        uk[i].append(word)\n",
        "    processed.append(vect)\n",
        "  out = abs(processed[0]-processed[1])\n",
        "  i = len(set(uk[0])-set(uk[1])) + len(set(uk[1])-set(uk[0]))\n",
        "  out = out + i*ones(100)\n",
        "  return out\n",
        "\n",
        "#Preprocessiong\n",
        "vectorData_train = []; labels_train = []\n",
        "for w in train_data:\n",
        "  vectorData_train.append(preProcess(w)) \n",
        "  labels_train.append(w[2])\n",
        "vectorData_train = array(vectorData_train)\n",
        "labels_train = array(labels_train)\n",
        "labels_train = labels_train*2 - ones(len(labels_train))\n",
        "\n",
        "vectorData_test = []; labels_test = []\n",
        "for w in test_data:\n",
        "  vectorData_test.append(preProcess(w)) \n",
        "  labels_test.append(w[2])\n",
        "vectorData_test = array(vectorData_test)\n",
        "labels_test = array(labels_test)\n",
        "labels_test = labels_test*2 - ones(len(labels_test))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RG1Vs1-lcCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6e27ee9-dd76-4752-91bd-24bd62241aae"
      },
      "source": [
        "#Logistic Regression\n",
        "reg = LogisticRegression(max_iter=1000).fit(vectorData_train, labels_train)\n",
        "train = reg.score(vectorData_train, labels_train)\n",
        "test = reg.score(vectorData_test, labels_test)\n",
        "\n",
        "print( 'Train accuracy: '+ str(100*train) + '%')\n",
        "print( 'Test accuracy: '+ str(100*test) + '%')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 67.35015772870663%\n",
            "Test accuracy: 66.89748979844194%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri-L2ulDlkkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9ae5831-32db-4805-96b2-a9f92074c537"
      },
      "source": [
        "#Polynomial logistic Regression\n",
        "def transform(data,T):\n",
        "  out = data\n",
        "  for i in range(2,T+1):\n",
        "    out = concatenate((out, data**i), axis=1)\n",
        "  return out\n",
        "T=2\n",
        "reg = LogisticRegression(random_state=0,max_iter=10000).fit(transform(vectorData_train,T), labels_train)\n",
        "train = reg.score(transform(vectorData_train,T), labels_train)\n",
        "test = reg.score(transform(vectorData_test,T), labels_test)\n",
        "\n",
        "print( 'Train accuracy: '+ str(100*train) + '%')\n",
        "print( 'Test accuracy: '+ str(100*test) + '%')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 68.6422141373284%\n",
            "Test accuracy: 68.09199950537901%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh9AjFG7umHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8a6eeb4-6b27-43bf-983b-2fb9ec3dc302"
      },
      "source": [
        "#Random forest\n",
        "reg = RandomForestClassifier(max_depth = 20,random_state=0).fit(vectorData_train, labels_train)\n",
        "train = reg.score(vectorData_train, labels_train)\n",
        "test = reg.score(vectorData_test, labels_test)\n",
        "\n",
        "print( 'Train accuracy: '+ str(100*train) + '%')\n",
        "print( 'Test accuracy: '+ str(100*test) + '%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 97.61593334725596%\n",
            "Test accuracy: 69.99381723754173%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHEed0J5n6mW",
        "colab_type": "text"
      },
      "source": [
        "# Bad Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWVT3EJuULS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3016e95d-0f00-4ea5-e141-47679cd4e89f"
      },
      "source": [
        "#Adaboost\n",
        "reg = AdaBoostClassifier(n_estimators=10, random_state=0).fit(vectorData_train, labels_train)\n",
        "train = reg.score(vectorData_train, labels_train)\n",
        "test = reg.score(vectorData_test, labels_test)\n",
        "\n",
        "print( 'Train accuracy: '+ str(100*train) + '%')\n",
        "print( 'Test accuracy: '+ str(100*test) + '%')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 66.47303223820882%\n",
            "Test accuracy: 65.79943118585383%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}